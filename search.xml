<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis 持久化机制]]></title>
    <url>%2Fwiki-site%2Fwiki%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FRedis%20%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Redis 是一款基于内存的键值对数据库，使用单线程IO多路复用技术达到高性能。但某些场景下对数据的持久性是有要求的，所以Rdis提供了两种持久化策略，防止宕机数据丢失。 Redis 持久化机制对于persistence持久化存储，Redis提供了两种方式： RDB(Redis database) 存储快照文件snapshot AOF(Append-only file) 存储redo文件 1. RDBRBD 是在规定时间点将内存数据通过快照方式写入临时文件，再替换上次的持久化文件，达到数据持久化的方式。 优点： 使用fork出的子进程处理，不影响主进程 输出snapshot快速且体积小缺点： RDB间隔一段时间执行，如果在执行期间发生故障，将导致数据丢失 当内存数据较大时，fork操作将花费较长时间，导致Redis无法提供服务 RDB 会在指定的情况下触发快照 配置的快照间隔时间 12345678910111213141516## RDB默认是开启的## RDB文件名dbfilename dump.db## RDB文件存储目录dir ./## RDB快照触发时机, save &lt;间隔时间&gt; &lt;操作数&gt;## 全部删除即关闭RDBsave 900 1## RDB快照异常时, 是否阻塞客户端"变更操作"stop-writes-on-bgsave-error yes## RDB文件是否进行压缩rdbcompression yes 执行 save 或 bgsave 时 12345## 同步进行./redis-cli -h ip -p port save## 异步进行./redis-cli -h ip -p port bgsave 执行 flushall 时 执行master/slave全量复制时 快照的实现原理 Redis使用fork复制一份当前进程的副本(子进程)。 父进程继续接收处理客户端请求，子进程开始将内存的数据写入到临时文件。 子进程用临时文件替换原文件。 注意：redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。 这就使得我们可以通过定时备份RDB文件来实现redis数据库的备份， RDB文件是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。 2. AOFAOF 将”操作+数据”以格式化(RESP)的方式最佳到操作日志文件尾部，在append操作成功后才进行实际数据的变更。当Server需要恢复时，可以直接replay日志文件，即可还原所有操作过程。 优点： 可以保持更高的数据完整性，如果设置间隔1S则最多丢失1S的数据。 可以手动删除其中某些命令，方便维护缺点： 额外的IO操作，略微影响Redis性能 AOF文件比RDB文件大 恢复速度慢，要逐条重放命令 AOF 默认关闭，开启时需要修改配置文件；12345## 开启aofappendonly yes## 指定aof文件名称appendfilename appendonly.aof AOF 文件重写在开启AOF时，命令会一直append到aof文件中，使得aof文件体积越来越大，Redis支持对aof文件进行重写(rewrite)，合并相同Key的操作，保留最小命令集合。1234567##aof文件rewrite触发的最小文件尺寸(mb,gb),只有大于此aof文件大于此尺寸是才会触发rewrite，默认“64mb”，建议“512mb” auto-aof-rewrite-min-size 64mb ##相对于“上一次”rewrite，本次rewrite触发时aof文件应该增长的百分比。 ##每一次rewrite之后，redis都会记录下此时“新aof”文件的大小(例如A)，那么当aof文件增长到A*(1 + p)之后 ##触发下一次rewrite，每一次aof记录的添加，都会检测当前aof文件的尺寸。 auto-aof-rewrite-percentage 100 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 同步磁盘数据 Redis每次更改数据的时候都会将命令记录到aof文件，但是实际上由于kernel的缓存机制，数据并没有实时写入到硬盘，而是进入硬盘缓存,再通过硬盘缓存机制去刷新到保存到文件。 12345678 ## 每次执行写入都会进行同步 ， 这个是最安全但是是效率比较低的方式 # appendfsync always ## 每一秒执行appendfsync everysec ## 不主动进行同步操作，由操作系统去执行，这个是最快但是最不安全的方式# appendfsync no aof文件损坏后怎么恢复 Redis 在执行命令中途宕机，导致命令只存储到aof一半，这个时候通过aof文件无法恢复，需要先对文件进行修复。 aof文件修复可以使用Redis提供的工具： 12## bin/redis-check-aof --fix 3. RDB和AOF如何选择 一般来说,如果对数据的安全性要求非常高的话，应该同时使用两种持久化功能。如果可以承受数分钟以内的数据丢失，那么可以只使用 RDB 持久化。有很多用户都只使用 AOF 持久化， 但并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快 。两种持久化策略可以同时使用，也可以使用其中一种。如果同时使用的话， 那么Redis重启时，会优先使用AOF文件来还原数据。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 集群]]></title>
    <url>%2Fwiki-site%2Fwiki%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FRedis%20%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[Redis 是一个开源的 key-value 存储系统，由于出众的性能，大部分互联网企业都用来做服务器端缓存。Redis 在3.0版本前只支持单实例模式，虽然支持主从模式、哨兵模式部署来解决单点故障，但是现在互联网企业动辄大几百G的数据，可完全是没法满足业务的需求，所以，Redis 在 3.0 版本以后就推出了集群模式。 一、Master-slave 模式实现主从复制模式，只需要在slave服务器上修改配置文件：12## 配置master服务器slaveof &lt;masterip&gt; &lt;masterport&gt; slave服务器只接收读请求，可以用来做读写分离，通过sync命令向master同步数据。 配置完成后启动，可以通过命令查看状态：12## 输出当前服务信息info replication 数据同步从节点定时(1S)从主节点同步数据，通过发送sync命令, 通过命令可以监控同步信息： 1replconf listening –port 6379 可以使用命令手动同步数据：sync. 数据同步方式 基于RDB文件的复制(第一次连接或重启的时候) 无硬盘复制 repl-diskless-sync yes 增量复制 PSYNC master run id. Offset 实现原理 slave 第一次或者重连到 master 上以后，会向 master 发送一个SYNC的命令 master 收到SYNC的时候，会做两件事： 执行bgsave（rdb的快照文件） master 把新收到的修改命令存入到缓冲区, 通过RESP协议发送给 slave (aof方式) slave 收到文件后会先清空数据，再从rdb快照文件恢复 缺点：主从复制的模式无法对 master 进行动态选举。 二、哨兵模式Redis 提供了哨兵工具，监控 master 和 salve 是否正常运行,如果 master 出现故障，那么会把其中一台 salve 数据升级为 master。 哨兵机也可做集群防止单点问题，启动哨兵的步骤： 拷贝哨兵配置文件 sentinel.conf 修改配置文件 12## 配置主节点名称、ip、port、master需要的投票数sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; 启动哨兵 1bin/redis-sentinel sentinel.conf 三、Redis 集群Redis 集群采用了P2P的模式，完全去中心化。Redis 把所有的 Key 分成了 16384 个 slot，每个 Redis 实例负责其中一部分 slot 。集群中的所有信息（节点、端口、slot等），都通过节点之间定期的数据交换而更新。Redis 客户端可以在任意一个 Redis 实例发出请求，如果所需数据不在该实例中，通过重定向命令引导客户端访问所需的实例。 修改配置文件，采用集群方式：1234567891011## 节点标识pid 6379和port要对应pidfile /var/run/redis_6379.pid## 启动集群模式cluster-enabled yes## 集群配置文件cluster-config-file nodes-6379.conf## 集群节点连接超时cluster-node-timeout 15000 启动每个redis服务，尝试使用命令，发现集群还无法使用，提示信息： 1(error) CLUSTERDOWN Hash slot not served Redis 节点虽然启动了，但是它们之间还无法相互发现，也无法分配slot，需要一个中间人调度。 安装集群所需软件由于 Redis 集群需要使用 ruby 命令，所以我们需要安装 ruby 和相关接口。 123yum install rubyyum install rubygemsgem install redis 调用 ruby 命令创建集群： 1bin/redis-trib.rb create --replicas 1 192.168.56.110:6379 192.168.56.110:6380 192.168.56.120:6379 192.168.56.120:6380 192.168.56.130:6379 192.168.56.130:6380 --replicas 1 表示主从复制比例为 1:1, 所以这里需要有6个 Redis 服务节点，组成3主3从的集群。 验证一下依然是通过客户端命令连接上，通过集群命令看一下状态和节点信息等。 123bin/redis-cli -c -h 192.168.56.110 -p 6379cluster infocluster nodes 四、其它集群方案一致性哈希通过程序对Key进行一致性哈希，再路由到不同的 Redis 服务节点上。 redis-sharddingJedis封装的基于一致性哈希算法的解决方案，通过ShareddingJedis客户端连接到服务节点，也是在应用层面实现的。 codis基于 redis-2.8 开发的 codis-server，支持了数据的分片存储，通过codis-proxy实现请求路由。 twemproxytwitter 提供的解决方案，也是通过增加 proxy 代理层，做数据分片存储和请求路由。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka quickstart]]></title>
    <url>%2Fwiki-site%2Fwiki%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FKafka%20quickstart%2F</url>
    <content type="text"><![CDATA[1. Kafka是什么? Apache Kafka® is a distributed streaming platform. Kafka是一个高性能、高吞吐量的分布式消息通信系统。常用于系统的日志收集分析、消息通信、用户行为分析、服务器指标监控、流式处理等。 2. Kafka集群安装 下载kafka二进制安装包, 并解压到 /usr/local目录下。 进入到config目录下修改server.properties配置文件： broker.id 在集群中的唯一编号 listeners 本机ip num.partitions 默认的topic分区数 zookeeper.connect 连接到zookeeper集群，可以设置根路径 ip:port/kafka 进入到bin目录下，以守护进程方式启动。1$ sh kafka-server-start.sh -daemon ../config/server.properties 3. Kafka基本操作 创建一个topic 1$ sh kafka-topics.sh --create --zookeeper 192.168.56.110:2181/kafka --replication-factor 1 --partitions 2 --topic first-topic 列出所有topic 1$ sh kafka-topics.sh --list --zookeeper 192.168.56.110:2181/kafka 生成者发送消息 1$ sh kafka-console-producer.sh --broker-list 192.168.56.110:9092 --topic first-topic 消费者接收消息 1$ sh kafka-console-consumer.sh --bootstrap-server 192.168.56.110:9092 --topic first-topic --from-beginning 查看消息日志 1$ sh kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/first-topic-0/00000000000000000000.log --print-data-log 4. Kafka中的概念Message消息是 Kafka 中最基本的数据单元，由 Key/Value 组成(byte[])，根据Key的哈希值路由到不同区间进行存储。Kafka 会对消息进行压缩和批量发送。 Topictopic 是用于存储消息的逻辑单元，可以看作一个消息集合，每个 topic 可以有多个生产者向其推送消息，也可以有任意多个消费者。 Partition每个 topic 可以划分多个分区，即 Kafka 存储消息的物理单元。Partition 是以文件的形式存储在 kafka-logs 目录下，命名规则是 &lt;topic_name&gt;-&lt;partition_id&gt;。 GroupKafka 中的逻辑分组，同一个组内的一条消息只被一个组员消费，并且共同维护 consumer offset。不同组内的消费者可以同时消费同一条消息，实现 pub/sub 模式。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka 实现原理]]></title>
    <url>%2Fwiki-site%2Fwiki%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FKafka%20%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[1. 消息可靠性机制消息发送可靠性消息发送到 broker 有三种确认方式 request.required.acks ： acks=0 producer 不会等待 broker 发送ack，既可能丢失也可能重发。 acks=1 当 leader 接收到消息后发送ack，可能重发。 acks=-1 当所有 follower 同步成功后发送ack，丢失消息可能性低。 消息存储可靠性每一条消息发送到broker中，会跟据partition规则存储到对应分区，如果规则设置合理可以实现消息均匀分布到不同分区，实现存储的水平扩展。高可靠性的保障来自另一个叫副本(replication)策略，通过设置(–replication-factor)参数设置。 2. 副本存储机制Kafka 在创建 topic 支持设置对应的副本个数 --replication-factor，会生成对应的分区副本数交叉存储在每个节点上。 副本存活条件 副本所有节点必须和zookeeper保持连接状态 副本的最后一条消息的offset和leader的最后一条消息的offset之间差值不能超过设定值replica.lag.max.messages 如何同步消息第一个启动的节点成功在zookeeper中注册信息成为leader对外提供服务，其它replica做为follower要定时同步数据。 HW(high watermark) ：表示所有follower已同步完成的offset位置 LEO(Log End Offset) ：表示leader节点当前消息的offset位置 consumer只能消费所有follower已同步完成的数据，即HW标注的位置。 如何均匀分布Kafka 为了更好的做到负载均衡，会尽量把所有的 partition 均匀分配到整个集群上，分配的算法： 把所有 broker(n) 和 partition(n) 排序 把第i个partition分配到 (i%n) 个broker上 把第 i 个 partition 的第 j 个 replica 分配到 ((i+j) % n) 个broker上 如何处理所有副本不工作情况在ISR中至少有一个follower工作时，Kafka可以确保消息不丢失，但如果某个分区所有备份都宕机了，采取以下措施： 等待ISR中任意一个follower活过来，并且选择它为leader 选择任意一个replica(不一定是ISR中的)活过来作为leader 这两种需要在可用性和一致性当中做一个选择。 3. Kafka 文件存储机制partition每个partition为一个目录，命名规则为 &lt;topic_name&gt;-&lt;partition_no&gt;，存储在 kafka_logs 目录下。 segmentKafka 为防止分区文件过大，又将分区拆分为 segment 存储，一个segment文件.index和.log两部分组成，即索引文件和数据文件。segment 文件由64位long数值命名，文件名即记录的最大 offset 值，查找时先通过定位 offset 落的范围，再进入文件查找。 日志保留Kafka 中无论是否消费了消息(只是移动了 offset)，都会一直保留这些消息，为了避免磁盘爆满，使用相应的保留策略(retention policy)，以实现周期性的删除陈旧消息： 根据消息保留时间，超过指定时间则删除 根据 topic 大小，超过阈值开始删除最旧消息 日志压缩Kafka 会定期将相同 Key 的消息进行合并，只保留最新的 Value 值。 4. Kafka 消息的消费原理旧版本的 Kafka 将 Consumer group 的消费进度记录在 zookeeper 中，导致对 zookeeper 频繁的写入而性能低下。新版本1.0+已修改为记录在对应 topic 目录下，默认创建了50个 __consumer_offset_topic 文件夹，将消费的进度 offset 保存在对应的文件中。 计算 consumer group 的哈希值 1Math.abs("group1".hashCode() % 50) 根据哈希值找到对应的__consumer文件，查看消费进度 1sh kafka-simple-consumer-shell.sh --topic __consumer_offsets --partition 15 -broker-list 192.168.56.110:9092,192.168.56.120:9092,192.168.56.130:9092 --formatter kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter 5. Kafka 的消费者分区分配策略Kafka中存在 consumer group 的概念，也就是group.id一样的consumer属于一个consumer group，组内的所有消费者协调在一起来消费消费订阅主题的所有分区。当然每一个分区只能由同一个消费组内的consumer来消费，那么同一个consumer group里面的consumer是怎么去分配该消费哪个分区里的数据，这个就设计到了kafka内部分区分配策略（Partition Assignment Strategy）。在 Kafka 内部存在两种默认的分区分配策略：Range（默认） 和 RoundRobin。通过：partition.assignment.strategy指定 两种分区策略Range （默认策略）0 ，1 ，2 ，3 ，4，5，6，7，8，9c0 [0,3]c1 [4,6]c2 [7,9]10(partition num)/3(consumer num) =3 RoundRobin （轮询）0 ，1 ，2 ，3 ，4，5，6，7，8，9c0,c1,c2c0 [0,3,6,9]c1 [1,4,7]c2 [2,5,8]kafka 的key 为null， 是随机｛一个Metadata的同步周期内，默认是10分钟｝ 6. 高吞吐量原因 消息顺序存储，通过 offset 偏移量进行顺序读取，减少机械硬盘磁柱移动。 消息批量发送，在异步模式中允许进行批量发送消息，先将消息缓存到内存，再一次请求中批量发送出去，减少磁盘读写和网络传输。 batch.size 每批量发送的数据大小 linger.ms 批量发送的间隔时间 消息的零拷贝，使用 FileChannel.transferTo 直接将消息发送到 socket buffer 中，省略了将消息读取到内存的过程。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis quickstart]]></title>
    <url>%2Fwiki-site%2Fwiki%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FRedis%20quickstart%2F</url>
    <content type="text"><![CDATA[1. Redis 是什么？ Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. Redis 是一个开源的分布式键值对(key/value)存储数据库，常用于做为数据缓存、单点登录、网站访问排名、秒杀抢购、应用模块开发等。 2. 安装 Redis 下载 redis-4.0.12.tar.gz 安装包 解压并进行编译测试make &amp;&amp; make test 安装到指定目录cd src &amp;&amp; make install PREFIX=/usr/local/redis-4.0.12 make install安装完成后会在指定目录下生成bin/文件夹，里面存放着使用 redis 的工具。 3. 启动和停止 Redis 首先到源目录下拷贝配置文件到安装目录cp ~/redis-4.0.12/redis.conf /usr/local/redis-4.0.12/ 修改配置信息 bind： IP绑定修改为本机IP daemonize： 改为后台进程运行 启动 redis 服务./redis-server ../redis.conf 使用可以端连接到 redis./redis-cli -h 192.168.56.110 -p 6379 停止 redis 服务./redis-cli shutdown 4. 常用命令Key 相关keys 检索满足条件的键值对，支持正则表达式的通配符匹配，但要注意大数据量下的检索影响 redis 服务性能。123456## 获得一个符合匹配规则的键名列表，支持通配符keys [? / * [] ]## 判断key是否存在exists key## 获取key结构类型type key 字符类型最基本的数据结构，可以存储任意的字符类型的数据，单条数据最大可支持512M。12345678910111213141516171819202122## 设置key/value键值, 过期时间 EX=10s, PX=100msset key value EX 10 PX 100 ## 批量设置多个key/valuemset key value key1 value1## 只在key不存在时进行设置setnx key value## 获取key值get key## 获取多个key的值mget key key1## 对数字类型原子递增 1incr num## 原子递减 1decr num## 原子递增 10incrby num 10## 原子递减 10decrby num 10## 向指定的key追加字符串append key value## 获取key对应的value的长度strlen key 列表类型list 可以存储一个有序的字符列表，内部是使用双向链表实现的，可以用来实现分布式消息队列。命令以 l-开头。123456789101112## 左右两端添加数据(r|l)push key value value1 value2## 左右两端弹出数据，输出弹出的value(r|l)pop key## 获取列表长度llen key## 获取列表元素，start 开始索引， stop 结束索引(-1表示最右边)lrange key start stop## 从列表中移除N个value值的元素lrem key count value## 更新idx位置处的元素为valuelset key idx value 散列类型散列类型是 HashMap 数据结构，存储多个键值对，适合存储多属性对象，但不支持数据类型的嵌套。命令以 h- 开头。123456789101112## 设置对象field属性值hset key field valuehmset key field value field2 value2## 获取field属性值hget key fieldhmget key field field2## 获取所有field值hgetall key## 判断field属性是否存在hexists key field 集合类型集合类型 set 与列表不同，不能存在重复的数据，而且是无序存储。命令以 s- 开头。12345678910111213141516## 增加元素，如果value存在则忽略，返回成功加入集合的数量sadd key value value2## 删除元素srem key value## 获取所有元素smembers key## 获取集合长度scard key## 集合key1与key2的差集，列出key1中存在而在key2中不存在的元素sdiff key1 key2## 将差集存储在des中sdiffstore des key key2## 集合key1与key2的交集sinter key1 key2## 集合key1与key2的并集sunion key1 key2 有序集合类型有序集合是在集合set的基础上，增加了排序功能，增加了score表示元素的优先级。命令以 z- 开头。1234## 增加元素，优先级 scorezadd key score value## 列出集合，并且输出优先级zrange key start stop withscores 事务处理Redis 中支持事务，将多个命令加入到QUEUED中到最后一起提交或回滚，但有特例的情况无法回滚(命令运行时出错)。12345## 开启事务multi...## 提交事务exec 过期时间Redis 中可以对每个键值设置对应的过期时间。1234## 设置key过期时间为seconds秒expire key seconds## 获得key的过期时间,-1 未设置 -2已过期 ttl key 发布订阅(pub/sub)Redis 中支持消息的发布订阅模式，类型消息中间件的功能，但性能不高一般不推荐使用。1234## 发布消息到channel频道publish channel msg## 订阅channel频道的消息subscribe channel]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ configuration]]></title>
    <url>%2Fwiki-site%2Fwiki%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FActiveMQ%20configuration%2F</url>
    <content type="text"><![CDATA[ActiveMQ使用过程中涉及到的一些配置信息。 1. 传输协议配置支持 TCP, UDP, NIO, SSL, HTTP(S), VM 等协议.1234&lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name="nio" uri="nio://0.0.0.0:61618?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600" /&gt;&lt;/transportConnectors&gt; 2. 持久化策略配置支持的持久化方式有 kahaDB, AMQ, JDBC, Memory. 使用 AMQ 文件存储123&lt;persistenceAdapter&gt; &lt;amqPersistenceAdapter directory="$&#123;activemq.data&#125;/amq" maxFileLength="32m"/&gt; &lt;/persistenceAdapter&gt; 使用 JDBC 存储使用jdbc数据库存储的方式，需要连接到对应的数据源，要在../lib下加入连接包。123456789101112&lt;!-- jdbc存储策略 --&gt;&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource="#mysqlDataSource" createTablesOnStartup="true" /&gt;&lt;/persistenceAdapter&gt;&lt;!-- 数据源配置 --&gt;&lt;bean id="mysqlDataSource" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver" /&gt; &lt;property name="url" value="jdbc:mysql://192.168.56.104:3306/practice_dev" /&gt; &lt;property name="username" value="root" /&gt; &lt;property name="password" value="123456" /&gt; &lt;/bean&gt; 3. 集群配置配置多态activemq服务进行联通，提高消息服务的性能。1234&lt;!-- broker 添加此配置 --&gt;&lt;networkConnectors&gt; &lt;networkConnector uri="static://(tcp://192.168.56.110:61616,tcp://192.168.56.120:61616)" /&gt;&lt;/networkConnectors&gt; 配置集群后，当使用某一个节点消费时，会将另外节点的数据转移到此节点上，导致在原节点无法再消费。此时需要配置==消息回流==123456&lt;!-- 消息回流支持，添加在 policyEntries下--&gt;&lt;policyEntry queue="&gt;" enableAudit="false"&gt; &lt;networkBridgeFilterFactory&gt; &lt;conditionalNetworkBridgeFilterFactory replayWhenNoConsumers="true" /&gt; &lt;/networkBridgeFilterFactory&gt;&lt;/policyEntry&gt; 4. zk+activemq高可用配置使用ZK进行master/slaver选举管理，在ZK中维护了临时有序节点，最先启动的先获得master。 directory： levelDB数据文件存储的位置 replicas：计算公式（replicas/2）+1 ， 当replicas的值为2的时候， 最终的结果是2. 表示集群中至少2台是启动时才能提供服务 bind: 用来负责slave和master的数据同步的端口和ip zkAddress： 表示zk的服务端地址 hostname：本机ip1234567&lt;persistenceAdapter&gt; &lt;replicatedLevelDB directory="$&#123;activemq.data&#125;/levelDB" replicas="2" bind="tcp://0.0.0.0:61615" zkAddress="192.168.56.110:2181" hostname="192.168.56.110" zkPath="/activemq/leveldb" /&gt;&lt;/persistenceAdapter&gt; 5. hawtio 监控服务 拷贝hawtio.war包到webapps目录下. 添加jetty容器映射rewriteHandler: 12345&lt;bean class="org.eclipse.jetty.webapp.WebAppContext"&gt; &lt;property name="contextPath" value="/hawtio" /&gt; &lt;property name="war" value="$&#123;activemq.home&#125;/webapps/hawtio.war" /&gt; &lt;property name="logUrlOnStart" value="true" /&gt; &lt;/bean&gt; 修改 bin/env 文件添加参数 需要注意的是-Dhawtio的三个设定必须放在ACTIVEMQ_OPTS设置的最前面(在内存参数设置之后),否则会出现验证无法通过的错误(另外,ACTIVEMQ_OPTS的设置语句不要回车换行) 1-Dhawtio.realm=activemq -Dhawtio.role=admins -Dhawtio.rolePrincipalClasses=org.apache.activemq.jaas.GroupPrincipal]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 应用篇]]></title>
    <url>%2Fwiki-site%2Fwiki%2F%E5%88%86%E5%B8%83%E5%BC%8F%2Fzookeeper%20%E5%BA%94%E7%94%A8%E7%AF%87%2F</url>
    <content type="text"><![CDATA[实际应用zookeeper 实际应用非常的广泛，只要涉及到分布式系统中的问题，都可以尝试使用 zookeeper 解决。 但 zookeeper 不是内存数据库，存储的内容应该都是比较简短的配置信息，zookeeper 的常用应用如下： 配置管理中心 软负载均衡 分布式锁 master选举 分布式队列 1. 配置管理中心在分布式系统中，多个服务运行在不同的服务器上，这时候再使用 application.properties 文件进行配置管理，将会非常的繁琐和易出错。使用 zookeeper 做为统一的配置中心，可以实现配置信息动态设置，多服务节点切换等功能。 实现思路 开源配置中心实现：disconf 创建统一个节点 /configure 作为配置信息的根节点。 客户端启动时拉取(pull)所有的子节点，载入到内存进行缓存。 启动后的客户端，对关注的配置节点进行 watch 获取到后续动态更新的配置信息(push)。 可以按module划分配置信息节点树。 2. 分布式锁在分布式系统中，多个服务对同一资源进行争抢时要用到锁，防止因为并发操作导致数据出现的不一致行为。使用 zookeeper 可以优雅的思想分布式锁，而且性能堪比 redis 实现。 实现思路 开源分布式锁实现：curator lock 创建统一节点 /locks 作为业务锁的根节点。 当服务执行时，均在 locks 下创建临时有序节点。 当前序号最小的节点获得锁，序号大的监听上一个节点的删除事件 当捕获到删除事件，或 session 超时(临时节点特性，连接断开删除节点)时，后一个节点获得锁。 可以扩展做读写锁，分类锁，业务模块锁。 PS：如果使用创建同一节点的方式，会产生羊群效应，因为过多的服务请求涌入而压垮 zookeeper 集群。 3. master 选举在分布式系统中，为提高可用性通常可以使用冷备或热备的形式进行冗余，master-slaver模式下其实只有一个节点处理事务，而当 master 节点宕机后，热备的 slaver 自动顶替 master 节点进行处理。 实现思路 开源 master选举实现：curator selector 在服务器启动时，均到 zookeeper 参数创建临时节点 /master。 创建成功的服务器成为 master, 其它服务器进行事件监听。 当事件触发后，重新进行选举(热备自动切换)。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper quickstart]]></title>
    <url>%2Fwiki-site%2Fwiki%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FZookeeper%20quickstart%2F</url>
    <content type="text"><![CDATA[1. zookeeper 是什么？ ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. zookeeper 是Apache基金会的一个项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册，是分布式协调服务，目标是解决分布式数据的一致性问题。 2. zookeeper 能做什么？数据的发布/订阅(配置中心 disconf)、 负载均衡(dubbo)、唯一ID生成器、统一命名服务、master选举(kafka, hadoop, hbase)、分布式队列、分布式锁…… 3. zookeeper 的特性 zookeeper 用来做的任务都是由他的特性决定的，理解了他的特性就可以根据实际的场景选择具体的方案。 顺序一致性：从客户端发起的事务请求，严格按照顺序被应用到zookeeper中 原子性：所有事务请求在集群上应用情况是一致的，要么都成功，要么都失败。 可靠性：一旦服务器应用了某个事务数据，那么这个数据一定是同步并且保留下来的。 实时性：一旦某个事务被成功应用，客户端能立即读取到最新数据状态(zookeeper 仅仅保证一定时间内的近实时性)。 4. 安装 zookeeper4.1 单机环境安装 下载安装包 zookeeper-3.4.12.tar.gz 解压安装包tar -zxvf zookeeper-3.4.12.tar.gz -C /usr/local/ 创建配置文件cd conf/ &amp;&amp; cp zoo_sample.cfg zoo.cfg 启动 zookeepercd bin/ &amp;&amp; sh zkServer.sh start 使用客户端连接到 zookeeper 进行操作sh zkCli.sh -server ip:port 单机环境下启动 zookeeper 状态为 standalone 仅用于测试或学习。 4.2 集群环境安装 集群环境下至少需要2N+1台服务器进行安装 修改配置文件，添加主机列表 123456……# ip:port:port # ip地址 : 用于节点通信的端口 : 用于选举的端口 [:observer]server.1 = 192.168.56.110:2888:3888server.2 = 192.168.56.120:2888:3888server.3 = 192.168.56.130:2888:3888 添加 myid 文件在配置文件的 dataDir 目录下创建 myid 文件，文件就一行数据内容是每台机器对应的server.ID的数字。 启动 zookeeper 4.3 zookeeper 节点类型 leader : 领导节点，主要接收、分发请求，发起事务处理投票，并给 follower 节点同步数据。 follower : 随从节点，处理读请求，转发事务请求，并保持和 leader 节点同步和事务的投票选举。 observer : 监控节点，处理读请求，保持和 leader 节点同步但不进行投票选举。 5. zookeeper 客户端命令使用12345678910111213141516# 列出路径下的所有节点ls / # 创建节点# -e 临时节点 -s 有序节点 acl 权限create [-e] [-s] path data acl# 获取节点信息get path# 更新节点内容# version 类似数据库乐观锁的实现set path data [version]# 删除节点delete path [version]]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统并发用户估算]]></title>
    <url>%2Fwiki-site%2Fwiki%2F%E5%88%86%E5%B8%83%E5%BC%8F%2F%E7%B3%BB%E7%BB%9F%E5%B9%B6%E5%8F%91%E7%94%A8%E6%88%B7%E4%BC%B0%E7%AE%97%2F</url>
    <content type="text"><![CDATA[泊松分布并发用户与最大并发用户计算： 1.平均并发用户数C = n*L/T n 为login session数 L 为login session平均时长 T 为考察时长 2.并发峰值用户数C’≈ C + 3*√200 3.吞吐量F=VU * R / T F为吞吐量 VU表示虚拟用户个数 R表示每个虚拟用户发出的请求数 T表示性能测试所用的时间 R = T / TS 例：假设有一个OA系统，该系统有3000个用户，平均每天大约有400个用户要访问该系统，对一个典型用户来说，一天之内用户从登录到退出该系统的平均时间为4小时，在一天的时间内，用户只在8小时内使用该系统。 根据公式计算得：C = 400 4/8 = 200C’≈200+3 √200 = 242]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop quickstart]]></title>
    <url>%2Fwiki-site%2Fwiki%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FHadoop%20quickstart%2F</url>
    <content type="text"><![CDATA[1. Hadoop 是什么？Hadoop是一个分布式系统架构，由Apache基金会基于Java开发。用户可以在不了解分布式底层细节的情况下，开发分布式程序，充分利用集群的威力高速运算和存储。 2. Hadoop 能做什么？Hadoop 可以解决海量数据的存储、海量的数据分析。例如：Yahoo! 的垃圾邮件识别和过滤、用户特征建模；Amazon.com（亚马逊）的协同过滤推荐系统；Facebook的Web日志分析；Twitter、LinkedIn的人脉寻找系统；淘宝商品推荐系统、淘宝搜索中的自定义筛选功能……这些应用都使用到Hadoop及其相关技术。 3. Hadoop 的构成3.1 HDFS 分布式文件系统HDFS有着高容错性的特点，并且设计用来部署在低廉的硬件上。而且它提供高传输率来访问应用程序的数据，适合那些有着超大数据集的应用程序。HDFS是一个 master/slave 的结构，在 master 上只运行一个 NameNode，而在每一个 slave 上运行一个 DataNode。 NameNode负责: 接受用户请求. 维护文件系统目录结构. 管理文件与Block间关系，Block与DataNode之间关系.(默认Block块大小为64M ) DataNode负责: 存储文件. 文件被分成Block存储在磁盘上. 为保证数据安全，文件会有多个副本. 3.2 MapReduce 并行计算框架MapReduce 是 Google 的一项重要技术, 它是一个编程模型，用于进行大数据计算，通常采用的处理手法是并行计算。MapReduce 是一个 master/slave 的结构，在 master上只运行一个 JobTracker ，而在每一个slave上运行一个 TaskTracker。 JobTracker 负责: 接收客户提交的计算. 把计算分配给 TaskTracker 执行. 监控 TaskTracker 的执行情况. TaskTracker 负责: 执行 JobTracker 分配的任务. 4. Hadoop 的特点 扩容能力：通过增加节点，扩容方便可靠. 成本低：可以通过普通机器组成服务器集群来处理数据. 高效率：通过分发数据，可以在数据所在节点上并行处理数据. 可靠性：可以自动维护数据的多个副本，并在任务失败后自动重新部署计算任务 5. 安装 Hadoop环境准备 安装 Jdk 下载 Apache Hadoop 解压并设置环境变量1234$ tar -zxvf hadoop-1.1.2.tar.gz$ export HADOOP_HOME=/usr/local/hadoop/hadoop-1.1.2 $ export PATH=.:$HADOOP_HOME/bin/:$JAVA_HOME/bin/:$PATH $ source /etc/profile 配置 修改 $hadoop_home/conf/hadoop-env.sh JAVA_HOME 配置 修改 $hadoop_home/conf/core-size.xml 123456789101112&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://joecnn:9000&lt;/value&gt; &lt;description&gt;your hostname&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/hadoop-1.1.2/tmp&lt;/value&gt; &lt;description&gt;your hadoop home&lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt; 修改 $hadoop_home/conf/hdfs-site.xml 12345678910111213141516171819202122&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; ``` 4. 修改 `修改 $hadoop_home/conf/mapred-site.xml````xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;chenquan:9001&lt;/value&gt; &lt;description&gt;change your hostname&lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt; 启动 Hadoop 格式化 HDFS 文件系统 hadoop namenode -format 启动 start-all.sh start-all.sh 启动所有的Hadoop守护。包括namenode, datanode, jobtracker, tasktrack stop-all.sh 停止所有的Hadoop start-mapred.sh 启动Map/Reduce守护。包括Jobtracker和Tasktrack stop-mapred.sh 停止Map/Reduce守护 start-dfs.sh 启动Hadoop DFS守护.Namenode和Datanode stop-dfs.sh 停止DFS守护 验证: jps 5个进程，namenode，datanode，jobtracker，tasktracker，secondarynamenodehadoop:50070/ 访问 hdfs webserver 页面hadoop:50030/ 访问 mapreduce webserver 页面 去除启动警告 查看 start-all.sh -&gt; hadoop-config.sh 修改 /etc/profile 增加 export HADOOP_HOME_WARN_SUPPRESS=1 source /etc/profile 刷新环境变量 验证： start-all.sh / stop-all.sh]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
</search>
